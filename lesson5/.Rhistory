head(mtcars)
tail(mtcars, 3)
mtcars$mpg
mean(mtcars$mpg)
gwtwd()
getwd()
summary(mtcars)
efficient <- subset(mtcars, mpg >= 23)
View(efficient)
str(mtcars)
str(efficient)
dim(efficient)
subset(mtcars, mpg < 14 | disp > 390)
subset(mtcars, mpg > 30 & hp > 100)
subset(mtcars, qsec <= 16.90)
lightCars <- subset(mtcars, wt < 2)
mtcars$year <- 1974
mtcars <- subset(mtcars, select = -year)
mtcars$year <- c(1973, 1974)
View(mtcars)
mtcars <- subset(mtcars, select = -year)
mtcars$wt
cond <- mtcars$wt < 3
cond
mtcars$weight_class <- ifelse(cond, 'light', 'average')
mtcars$weight_class
cond <- mtcars$wt > 3.5
mtcars$weight_class <- ifelse(cond, 'heavy', mtcars$weight_class)
mtcars$weight_class
rm(cond)
rm(efficient)
install.packages('knitr', dependencies = T)
library(knitr)
subset(mtcars, mpg >= 30 | hp < 60)
```{r}
install.packages('knitr', dependencies = T)
library(knitr)
```
install.packages('knitr', dependencies = T)
library(knitr)
install.packages("knitr", dependencies = T)
install.packages('knitr', dependencies = T)
library(knitr)
install.packages("knitr", dependencies = T)
data(diamonds)
library(ggplot2)
data(diamonds)
summary(diamonds)
View(diamonds)
load("~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/L4.RData")
#create data sets
diamonds_by_clarity <- group_by(diamonds, clarity)
diamonds_mp_by_clarity <- summarise(diamonds_by_clarity, mean_price = mean(price))
diamonds_by_color <- group_by(diamonds, color)
diamonds_mp_by_color <- summarise(diamonds_by_color, mean_price = mean(price))
#create plots
p1 = ggplot(aes(x = clarity, y = price), data = diamonds) +
geom_bar(stat = 'identity', aes(fill = clarity))
p2 = ggplot(aes(x = color, y = price), data = diamonds) +
geom_bar(stat = 'identity', aes(fill = color))
grid.arrange(p1,p2,ncol = 1)
library(ggplot2)
library(gridExtra)
library(dplyr)
library('alr3')
library(dplyr)
#create data sets
diamonds_by_clarity <- group_by(diamonds, clarity)
diamonds_mp_by_clarity <- summarise(diamonds_by_clarity, mean_price = mean(price))
diamonds_by_color <- group_by(diamonds, color)
diamonds_mp_by_color <- summarise(diamonds_by_color, mean_price = mean(price))
#create plots
p1 = ggplot(aes(x = clarity, y = price), data = diamonds) +
geom_bar(stat = 'identity', aes(fill = clarity))
p2 = ggplot(aes(x = color, y = price), data = diamonds) +
geom_bar(stat = 'identity', aes(fill = color))
grid.arrange(p1,p2,ncol = 1)
diamonds_by_cut <- group_by(diamonds, cut)
diamonds_mp_by_cut <- summarise(diamonds_by_cut, mean_price = mean(price))
p3 = ggplot(aes(x = cut, y = price), data = diamonds) +
geom_bar(stat = 'identity', aes(fill = cut))
grid.arrange(p1,p2,p3,ncol = 1)
workhours <- read.csv("~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson3/workinghours.csv")
names(workhours)
View(workhours)
gmp1 = ggplot(aes( x = year, y = value), data = workhours) +
geom_point(fill = 'orange')
gmp2 = ggplot(aes( x = country, y = value), data = workhours) +
geom_point(fill = 'red')
grid.arrange(gmp1,gmp2,ncol1)
gmp1 = ggplot(aes( x = year, y = value), data = workhours) +
geom_point(fill = 'orange')
gmp2 = ggplot(aes( x = country, y = value), data = workhours) +
geom_point(fill = 'red')
grid.arrange(gmp1,gmp2,ncol =1)
View(lightCars)
View(lightCars)
source('~/.active-rstudio-document', echo=TRUE)
table(pf$year_joined.bucket)
summary(pf$year_joined.bucket)
by(pf$friendships_initiated, pf$year_joined.bucket, mean(x))
by(pf, pf$year_joined.bucket, mean(pf$friendships_initiated))
by(pf, year_joined.bucket, mean(friendships_initiated))
by(pf, pf$year_joined.bucket, summmary)
by(pf, pf$year_joined.bucket, summary)
by(pf$friendships_initiated, pf$year_joined.bucket, summary)
by(pf$friendships_initiated, pf$year_joined.bucket, mean)
by(pf$prop_initiated, pf$year_joined.bucket, mean)
subset(pf, !is.na(pf$prop_initiated) )
by(subset(pf, !is.na(pf$prop_initiated)), pf$year_joined.bucket, mean)
by(subset(pf, !is.na(pf$prop_initiated)), pf$year_joined.bucket, mean)
subset(pf, !is.na(pf$prop_initiated))
propnum = subset(pf, !is.na(pf$prop_initiated))
by(propnum$prop_initiated, propnum$year_joined.bucket, mean)
# Create a scatter plot of the price/carat ratio
# of diamonds. The variable x should be
# assigned to cut. The points should be colored
# by diamond color, and the plot should be
# faceted by clarity.
# The plot should look something like this.
# http://i.imgur.com/YzbWkHT.jpg.
# Note: In the link, a color palette of type
# 'div' was used to color the histogram using
# scale_color_brewer(type = 'div')
# This assignment is not graded and
# will be marked as correct when you submit.
# ENTER YOUR CODE BELOW THIS LINE
# ===========================================
ggplot(data = diamonds, aes(x = cut, y = price/carat)) +
geom_point(aes(color = clarity)) +
facet_wrap(~clarity)
# Create a scatter plot of the price/carat ratio
# of diamonds. The variable x should be
# assigned to cut. The points should be colored
# by diamond color, and the plot should be
# faceted by clarity.
# The plot should look something like this.
# http://i.imgur.com/YzbWkHT.jpg.
# Note: In the link, a color palette of type
# 'div' was used to color the histogram using
# scale_color_brewer(type = 'div')
# This assignment is not graded and
# will be marked as correct when you submit.
# ENTER YOUR CODE BELOW THIS LINE
# ===========================================
ggplot(data = diamonds, aes(x = cut, y = price/carat)) +
geom_point(aes(color = clarity)) +
scale_x_log10() +
facet_wrap(~clarity) +
scale_color_brewer(type = "div")
# Create a scatter plot of the price/carat ratio
# of diamonds. The variable x should be
# assigned to cut. The points should be colored
# by diamond color, and the plot should be
# faceted by clarity.
# The plot should look something like this.
# http://i.imgur.com/YzbWkHT.jpg.
# Note: In the link, a color palette of type
# 'div' was used to color the histogram using
# scale_color_brewer(type = 'div')
# This assignment is not graded and
# will be marked as correct when you submit.
# ENTER YOUR CODE BELOW THIS LINE
# ===========================================
ggplot(data = diamonds, aes(x = cut, y = price/carat)) +
geom_point(aes(color = clarity)) +
facet_wrap(~clarity) +
scale_color_brewer(type = "div")
# Create a scatter plot of the price/carat ratio
# of diamonds. The variable x should be
# assigned to cut. The points should be colored
# by diamond color, and the plot should be
# faceted by clarity.
# The plot should look something like this.
# http://i.imgur.com/YzbWkHT.jpg.
# Note: In the link, a color palette of type
# 'div' was used to color the histogram using
# scale_color_brewer(type = 'div')
# This assignment is not graded and
# will be marked as correct when you submit.
# ENTER YOUR CODE BELOW THIS LINE
# ===========================================
ggplot(data = diamonds, aes(x = cut, y = price/carat)) +
geom_point(aes(color = color)) +
facet_wrap(~clarity) +
scale_color_brewer(type = "div")
# Create a scatter plot of the price/carat ratio
# of diamonds. The variable x should be
# assigned to cut. The points should be colored
# by diamond color, and the plot should be
# faceted by clarity.
# The plot should look something like this.
# http://i.imgur.com/YzbWkHT.jpg.
# Note: In the link, a color palette of type
# 'div' was used to color the histogram using
# scale_color_brewer(type = 'div')
# This assignment is not graded and
# will be marked as correct when you submit.
# ENTER YOUR CODE BELOW THIS LINE
# ===========================================
ggplot(data = diamonds, aes(x = cut, y = price/carat)) +
geom_point(aes(color = color), position = position_jitter(width = 0.4)) +
facet_wrap(~clarity) +
scale_color_brewer(type = "div")
hpi <- read.csv(file = 'hpi.csv')
names(hpi) = tolower(names(hpi))
names(hpi)
hpi <- read.csv(file = 'hpi.csv')
library(ggplot2)
library(gridExtra)
library(dplyr)
library('alr3')
library(dplyr)
workhours <- read.csv("~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson3/workinghours.csv")
hpi <- read.csv(file = '~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson3/hpi.csv')
hpi <- read.csv(file = '~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/hpi.csv')
names(hpi) = tolower(names(hpi))
names(hpi)
workhourssum <- workhours %>%
group_by(country) %>%
summarise(mean_hours = mean(value),
median_hours = median(as.numeric(value)),#necessary due to bug in version 0.4.1  (2015-01-14)
min_hours = min(value),
max_hours = max(value),
n = n()) %>%
arrange(max_hours)
merged = merge(workhourssum,hpi, by = 'country')
write.csv(merged, 'workhours_hpi.csv')
write.csv(merged, '~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/workhours_hpi.csv')
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
hourshpi <- load('~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/')
hourshpi <- load('~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/workhours_hpi.csv')
write.csv(merged, '~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/workhours_hpi.csv')
hpi <- read.csv(file = '~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/hpi.csv')
names(hpi) = tolower(names(hpi))
names(hpi)
workhourssum <- workhours %>%
group_by(country) %>%
summarise(mean_hours = mean(value),
median_hours = median(as.numeric(value)),#necessary due to bug in version 0.4.1  (2015-01-14)
min_hours = min(value),
max_hours = max(value),
n = n()) %>%
arrange(max_hours)
head(workhourssum)
tail(workhourssum)
workhourssum <- workhours %>%
group_by(country) %>%
summarise(mean_hours = mean(value),
median_hours = median(as.numeric(value)),#necessary due to bug in version 0.4.1  (2015-01-14)
min_hours = min(value),
max_hours = max(value),
n = n()) %>%
arrange(max_hours)
head(workhourssum)
tail(workhourssum)
workhourssum <- workhours %>%
group_by(country) %>%
summarise(mean_hours = mean(value),
median_hours = median(as.numeric(value)),#necessary due to bug in version 0.4.1  (2015-01-14)
min_hours = min(value),
max_hours = max(value),
n = n()) %>%
arrange(max_hours)
workhours <- read.csv("~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson3/workinghours.csv")
names(workhours)
workhourssum <- workhours %>%
group_by(country) %>%
summarise(mean_hours = mean(value),
median_hours = median(as.numeric(value)),#necessary due to bug in version 0.4.1  (2015-01-14)
min_hours = min(value),
max_hours = max(value),
n = n()) %>%
arrange(max_hours)
head(workhourssum)
tail(workhourssum)
merged = merge(workhourssum,hpi, by = 'country')
write.csv(merged, '~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/workhours_hpi.csv')
hourshpi <- load('~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/workhours_hpi.csv')
hourshpi <- load('~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/workhours_hpi.csv')
hourshpi <- load('~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/workhours_hpi.csv')
library(ggplot2)
library(gridExtra)
library(dplyr)
library('alr3')
library("GGally")
library('reshape2')
hourshpi <- load('~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/workhours_hpi.csv')
hourshpi <- read.delim('~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/workhours_hpi.csv')
View(hourshpi)
hourshpi <- read.csv('~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/workhours_hpi.csv')
View(hourshpi)
names(hourshpi)
View(hourshpi)
names(hourshpi[1])
names(hourshpi[11])
names(hourshpi[11]) = 'well.being'
names(hourshpi)
ognames <- names(hourshpi)
names(hourshpi[11]) <- 'well.being'
names(hourshpi[11, 13,17, 10, 12, 16]) <- c('well.being', 'footprint', 'governance.rank','life.expectancy', 'happy.life.years', 'gdp')
names(hourshpi)
names(hourshpi[11, 13,17, 10, 12, 16])
names(hourshpi[11, 13,17])
names(hourshpi[11])
names(hourshpi[11]) <- 'well.being'
names(hourshpi)
names(hourshpi)[11, 13,17, 10, 12, 16]
names(hourshpi)[11]
names(hourshpi)[11]
names(hourshpi)[11] <- 'well.being'
names(hourshpi)[13] <- 'footprint'
names(hourshpi)[17] <- 'governance.rank'
names(hourshpi)[10] <- 'life.expectancy'
names(hourshpi)[12] <- 'happy.life.years'
names(hourshpi)[16] <- 'gdp'
View(hourshpi)
View(hourshpi)
summary(hourshpi)
quantile(hourshpi)
names(hourshpi)
summary(hourshpi)
hourshpi$gdp_norm = hourshpi$gdp/hourshpi$population
quantile(hourshpi$gdp_norm)
ggplot(data = hourshpi, aes(x = hpi.rank)) +
geom_histogram(aes(fill = well.being ))  +
facet_wrap(~quantile(gdp_norm))
str(hourshpi)
ggplot(data = hourshpi, aes(x = hpi.rank)) +
geom_histogram(aes(fill = quantile(well.being) ))  +
facet_wrap(~sub.region)
ggplot(data = hourshpi, aes(x = well.being)) +
geom_histogram(aes(fill = hpi.rank)  +
facet_wrap(~sub.region)
ggplot(data = hourshpi, aes(x = well.being)) +
geom_histogram(aes(fill = hpi.rank))  +
facet_wrap(~sub.region)
ggplot(data = hourshpi, aes(x = well.being)) +
geom_histogram()  +
facet_wrap(~sub.region)
ggplot(data = hourshpi, aes(x = well.being)) +
geom_histogram(aes(color = hpi.rank))  +
facet_wrap(~sub.region)
quantile(hourshpi$hpi.rank)
quantile[1](hourshpi$hpi.rank)
quantile(hourshpi$hpi.rank)
hourshpi$hpi.rank_quantile <- quantile(hourshpi$hpi.rank)
table(hourshpi$hpi.rank)
table(hourshpi)
quantile(hourshpi$hpi.rank)
summary(hourshpi$hpi.rank)
quartile(hourshpi$hpi.rank)
quantile(hourshpi$hpi.rank)
summary(hourshpi$hpi.rank)
library(ggplot2)
library(gridExtra)
library(dplyr)
library('alr3')
library("GGally")
library('reshape2')
View(hpi)
setwd("~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson5")
hourshpi <- read.csv('~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/workhours_hpi.csv')
ognames <- names(hourshpi)
names(hourshpi)[11] <- 'well.being'
names(hourshpi)[13] <- 'footprint'
names(hourshpi)[17] <- 'governance.rank'
names(hourshpi)[10] <- 'life.expectancy'
names(hourshpi)[12] <- 'happy.life.years'
names(hourshpi)[16] <- 'gdp'
hourshpi$gdp_norm = hourshpi$gdp/hourshpi$population
names(hourshpi)
summary(hourshpi)
str(hourshpi)
quantile(hourshpi$gdp_norm)
quantile(hourshpi$hpi.rank)
summary(hourshpi$hpi.rank)
within(hourshpi, quartile <- cut(hpi.rank, quantile(hpi.rank, probs=0:4/4), include.lowest=TRUE, labels=FALSE))
View(hourshpi)
View(hourshpi)
hourshpi$hpi.rank_quartile <- within(hourshpi, hpi.rank_quartile <- cut(hpi.rank, quantile(hpi.rank, probs=0:4/4), include.lowest=TRUE, labels=FALSE))
View(hourshpi)
# The Gapminder website contains over 500 data sets with information about
# the world's population. Your task is to continue the investigation you did at the
# end of Problem Set 4 or you can start fresh and choose a different
# data set from Gapminder.
# If you’re feeling adventurous or want to try some data munging see if you can
# find a data set or scrape one from the web.
# In your investigation, examine 3 or more variables and create 2-5 plots that make
# use of the techniques from Lesson 5.
# You can find a link to the Gapminder website in the Instructor Notes.
# Once you've completed your investigation, create a post in the discussions that includes:
#       1. the variable(s) you investigated, your observations, and any summary statistics
#       2. snippets of code that created the plots
#       3. links to the images of your plots
# Copy and paste all of the code that you used for
# your investigation, and submit it when you are ready.
# ================================================================================
#read the data
hourshpi <- read.csv('~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson4/workhours_hpi.csv')
ognames <- names(hourshpi)
names(hourshpi)
names(hourshpi)[11] <- 'well.being'
names(hourshpi)[13] <- 'footprint'
names(hourshpi)[17] <- 'governance.rank'
names(hourshpi)[10] <- 'life.expectancy'
names(hourshpi)[12] <- 'happy.life.years'
names(hourshpi)[16] <- 'gdp'
hourshpi$gdp_norm = hourshpi$gdp/hourshpi$population
names(hourshpi)
hourshpi <- within(hourshpi, hpi.rank_quartile <- cut(hpi.rank, quantile(hpi.rank, probs=0:4/4), include.lowest=TRUE, labels=FALSE))
View(hourshpi)
hourshpi <- within(hourshpi, gdp_norm_quartile <- cut(hpi.rank, quantile(hpi.rank, probs=0:4/4), include.lowest=TRUE, labels=FALSE))
str(hourshpi)
hourshpi$hpi.rank_quartile <- factor(hourshpi$hpi.rank_quartile)
hourshpi$gdp_norm_quartile <- factor(hourshpi$gdp_norm_quartile)
str(hourshpi)
ggplot(data = hourshpi, aes(x = well.being)) +
geom_histogram(aes(color = hpi.rank_quartile))  +
facet_wrap(~sub.region)
ggplot(data = hourshpi, aes(x = well.being)) +
geom_histogram(aes(fill = hpi.rank_quartile))  +
facet_wrap(~sub.region)
ggplot(data = hourshpi, aes(x = well.being)) +
geom_histogram(aes(bindwidth = 1, fill = hpi.rank_quartile))  +
facet_wrap(~sub.region)
ggplot(data = hourshpi, aes(x = well.being)) +
geom_histogram(aes(binwidth = 1, fill = hpi.rank_quartile))  +
facet_wrap(~sub.region)
ggplot(data = hourshpi, aes(x = well.being)) +
geom_histogram(binwidth = 1, color = black,aes(fill = hpi.rank_quartile))  +
facet_wrap(~sub.region)
ggplot(data = hourshpi, aes(x = well.being)) +
geom_histogram(binwidth = 1, color = 'black',aes(fill = hpi.rank_quartile))  +
facet_wrap(~sub.region)
names(hourshpi)
ggplot(data = hourshpi, aes(x = well.being)) +
geom_histogram(binwidth = 1, color = 'black',aes(fill = hpi.rank_quartile))
hourshpi <- within(hourshpi, gdp_norm_quartile <- cut(gdp_norm, quantile(gdp_norm, probs=0:4/4), include.lowest=TRUE, labels=FALSE))
hourshpi <- within(hourshpi, hours_quartile <- cut(mean_hours, quantile(mean_hours, probs=0:4/4), include.lowest=TRUE, labels=FALSE))
hourshpi$gdp_norm_quartile <- factor(hourshpi$gdp_norm_quartile)
hourshpi$hours_quartile <- factor(hourshpi$hours_quartile)
str(hourshpi)
ggplot(data = hourshpi, aes(x = mean_hours)) +
geom_histogram(binwidth = 1, color = 'black',aes(fill = gdp_norm_quartile))  +
facet_wrap(~hpi.rank_quartile)
quantile(hourshpi$hpi.rank)
ggplot(data = hourshpi, aes(x = mean_hours)) +
geom_histogram(binwidth = 1, color = 'black',aes(fill = hpi.rank_quartile))  +
facet_wrap(~gdp_norm_quartile)
hourshpi <- within(hourshpi, gdp_quartile <- cut(gdp, quantile(gdp, probs=0:4/4), include.lowest=TRUE, labels=FALSE))
hourshpi$gdp_quartile <- factor(hourshpi$gdp_quartile)
View(hourshpi)
ggplot(data = hourshpi, aes(x = mean_hours)) +
geom_histogram(binwidth = 1, color = 'black',aes(fill = hpi.rank_quartile))  +
facet_wrap(~gdp_quartile)
names(hpi)
View(hpi)
View(workhours)
workhours$country
unique(workhours$country)
unique(workhours$country)[73]
unique(workhours$country)[1]
workhours$country[1]
workhours$country[73]
workhours$country[73] = 'Hong Kong'
workhours$country[73] <- 'Hong Kong'
workhours$country[73]
workhours <- read.csv("~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson3/workinghours.csv")
workhours$country[73]
workhours$country[73] = 'Hong Kong'
workhours <- read.csv("~/Udacity/dataAnalysisR/EDA_R_Udacity/lesson3/workinghours.csv")
unique(workhours$country)
workhours$country[73]
strsplit(workhours$country[73], ',')
workhours$country[73]
strsplit(workhours$country[73], ' ')
strsplit(workhours$country[73], 'H')
strsplit(workhours$country[73], "H")
typeof(workhours$country[73])
typeof(workhours$country)
strsplit(tostring(workhours$country[73], "H"))
ggplot(data = hourshpi, aes(x = mena_hours , y = hpi.rank)) +
geom_point(aes(color = gdp_quartile)) +
scale_colour_brewer(type = 'qual') +
#scale_x_continuous(limits = c(50,80), breaks = seq(50,80,2))
ggplot(data = hourshpi, aes(x = mena_hours , y = hpi.rank)) +
geom_point(aes(color = gdp_quartile)) +
scale_colour_brewer(type = 'qual')
#scale_x_continuous(limits = c(50,80), breaks = seq(50,80,2))
ggplot(data = hourshpi, aes(x = mena_hours , y = hpi.rank)) +
geom_point(aes(color = gdp_quartile)) +
scale_colour_brewer(type = 'qual')
ggplot(data = hourshpi, aes(x = mean_hours , y = hpi.rank)) +
geom_point(aes(color = gdp_quartile)) +
scale_colour_brewer(type = 'qual')
ggplot(data = hourshpi, aes(x = mean_hours , y = hpi.rank)) +
geom_point(aes(color = gdp_quartile))
help(transform)
ggplot(data = hourshpi, aes(x = mean_hours , y = hpi.rank)) +
geom_point(aes(color = gdp_quartile, size = well.being))
names(hourshpi)
ggplot(data = hourshpi, aes(x = mean_hours , y = hpi.rank)) +
geom_point(aes(color = gdp_quartile, size = well.being)) +
facet_wrap(~sub.region)
hourshpi <- within(hourshpi, happy.life_quartile <- cut(happy.life.years, quantile(happy.life.years, probs=0:4/4), include.lowest=TRUE, labels=FALSE))
hourshpi$happy.life_quartile <- factor(hourshpi$happy.life_quartile)
str(hourshpi)
facet_wrap(~happy.life_quartile)
ggplot(data = hourshpi, aes(x = mean_hours , y = hpi.rank)) +
geom_point(aes(color = gdp_quartile, size = well.being)) +
facet_wrap(~happy.life_quartile)
